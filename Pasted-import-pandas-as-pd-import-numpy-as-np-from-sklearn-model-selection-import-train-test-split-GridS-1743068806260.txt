import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc
from sklearn.externals import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from kerastuner.tuners import RandomSearch

# Default configurations and constants
DATA_PATH = "path/to/crispr_data.csv"
OUTPUT_PATH = "models/crispr_model.h5"

# Load data
def load_data(file_path):
    data = pd.read_csv(file_path)
    return data

# Feature Engineering
def preprocess_features(data):
    # Example feature engineering: combining various biological features and textual features
    numerical_features = data[['GC_content', 'off_target_score']]
    categorical_features = data[['cell_type', 'target_gene']]
    textual_features = data['guide_sequence'].apply(lambda x: ' '.join([str(a) for a in x]))
    
    transformers = [
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),
        ('text', TfidfVectorizer(), textual_features)
    ]
    
    preprocessor = ColumnTransformer(transformers=transformers)
    X = preprocessor.fit_transform(data)
    y = data['activity']  # Assuming 'activity' column indicates CRISPR efficiency
    
    return X, y

# Advanced Modeling
def build_models():
    # Define various models
    rf = RandomForestClassifier()
    gb = GradientBoostingClassifier()
    nn = MLPClassifier(hidden_layer_sizes=(100, 50), solver='adam', max_iter=200)
    keras_model = Sequential([
        Dense(100, input_dim=X_train.shape[1], activation='relu'),
        Dropout(0.2),
        Dense(50, activation='relu'),
        Dropout(0.2),
        Dense(1, activation='sigmoid')
    ])
    
    keras_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    # Model training pipelines
    pipelines = [
        ('RF', Pipeline([('preprocessor', preprocessor), ('classifier', rf)])),
        ('GB', Pipeline([('preprocessor', preprocessor), ('classifier', gb)])),
        ('NN', Pipeline([('preprocessor', preprocessor), ('classifier', nn)])),
        ('Keras', Pipeline([('preprocessor', preprocessor), ('classifier', keras_model)]))
    ]
    
    return pipelines

# Hyperparameter Tuning with Keras Tuner
def tune_hyperparameters(pipeline):
    tuner = RandomSearch(
        pipeline,
        objective='val_accuracy',
        max_trials=10,
        executions_per_trial=3,
        directory='keras_tuner',
        project_name='crispr_tuning'
    )
    
    tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val))
    
    best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]
    print(f"Best hyperparameters: {best_hps.values}")
    
    return tuner.hypermodel.build(best_hps.values)

# Main Execution
if __name__ == "__main__":
    # Load Data
    data = load_data(DATA_PATH)
    X, y = preprocess_features(data)
    
    # Split Data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

    # Build Models
    models = build_models()

    # Hyperparameter Tuning
    optimized_models = {}
    for name, model in models.items():
        print(f"\nTuning {name}...")
        optimized_model = tune_hyperparameters(model)
        optimized_models[name] = optimized_model.fit(X_train, y_train)

    # Model Evaluation
    for name, model in optimized_models.items():
        y_pred = model.predict(X_test)
        report = classification_report(y_test, y_pred)
        auc_score = roc_auc_score(y_test, y_pred)
        print(f"\nResults for {name}:")
        print(report)
        print(f"AUC Score: {auc_score}")
    
    # Save the Best Model (Keras-optimized)
    optimized_model = list(optimized_models.values())[0]
    optimized_model.save(OUTPUT_PATH)
